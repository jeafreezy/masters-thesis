{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "id": "dFZKrGTDHvSa"
         },
         "outputs": [],
         "source": [
            "\n",
            "\n",
            "# Data Analysis\n",
            "import pandas as pd\n",
            "import polars as pl\n",
            "import numpy as np\n",
            "\n",
            "# Visualization\n",
            "import seaborn as sns\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "\n",
            "# Stats & ML\n",
            "from scipy.stats import  zscore\n",
            "from sklearn.ensemble import IsolationForest\n",
            "\n",
            "\n",
            "\n",
            "pl.Config.set_tbl_rows(-1)\n",
            "%matplotlib inline"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "hyDedPc8HvSa"
         },
         "source": [
            "## Data Loading"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/"
            },
            "id": "2Xu83Mf6rT51",
            "outputId": "a9349bdc-5f4a-441a-b85c-6b299e155280"
         },
         "outputs": [],
         "source": [
            "try:\n",
            "    df = pl.read_csv('../exports/imputed_water_meters_v2.csv', infer_schema_length=100000)\n",
            "    print(f\"Data loaded successfully\")\n",
            "except Exception as e:\n",
            "    print(f\"An error occurred while loading the data: {e}\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "3VpS-O9vHvSb"
         },
         "source": [
            "# Exploratory Data Analysis"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 361
            },
            "id": "Jfr3pFLeHvSb",
            "outputId": "571b53ea-6a1e-4c06-9a2c-e0797e25b2af"
         },
         "outputs": [],
         "source": [
            "df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "-73wSk_NkPeQ"
         },
         "source": [
            "#### What is the total available data?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/"
            },
            "id": "zaZd8yFKHvSb",
            "outputId": "688b7b61-cecd-4fbb-956f-d0cdac8090d8"
         },
         "outputs": [],
         "source": [
            "df.shape[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/"
            },
            "id": "JtRUfptpcjXT",
            "outputId": "42e69189-d888-4cd2-f6f8-2392e5e8ed5e"
         },
         "outputs": [],
         "source": [
            "df['DEVICE_ID'].n_unique()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "am-tmDJMkUAt"
         },
         "source": [
            "#### What are some descriptive statistics about the data ?"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 487
            },
            "id": "aOu1qhsgHvSb",
            "outputId": "50756d1a-c802-4500-d1b4-b8746b6b3308"
         },
         "outputs": [],
         "source": [
            "df.describe()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "qFIOos31qDt2"
         },
         "source": [
            "#### Convert date string to Datetime"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/"
            },
            "id": "QI_aYc_CqWFv",
            "outputId": "55ee8b7f-15dc-4e17-a870-3a2338c4e1c9"
         },
         "outputs": [],
         "source": [
            "df = df.with_columns(\n",
            "    pl.col(\"DATE\").cast(pl.Date)\n",
            ")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df = df.rename({\n",
            "            \"DENORMALIZED_LIN_REG_IMPUTED\":\"LIN_REG_IMPUTED\",\n",
            "            #     \"DENORMALIZED_SAITS_IMPUTED\":\"SAITS_IMPUTED\",\n",
            "                \"DENORMALIZED_KNN_IMPUTED\":\"KNN_IMPUTED\",\n",
            "                \"CUMMULATIVE_CONSUMPTION_COPY\":\"CUMMULATIVE_CONSUMPTION\"\n",
            "               })"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Daily Consumption - for Validity"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "imputed_columns = [\n",
            "    \"MEAN_IMPUTED\", \"MEDIAN_IMPUTED\", \"FFILL_IMPUTED\", \"BFILL_IMPUTED\",\n",
            "    \"LINEAR_IMPUTED\", \"CUBIC_IMPUTED\", \"KNN_IMPUTED\",\n",
            "    \"LIN_REG_IMPUTED\", # \"SAITS_IMPUTED\"\n",
            "]\n",
            "\n",
            "# Loop through the imputed columns and calculate daily differences\n",
            "daily_diff_exprs = [\n",
            "    (pl.col(col) - pl.col(col).shift(1))\n",
            "    .over(\"DEVICE_ID\")\n",
            "    .alias(f\"DAILY_DIFF_{col}\")\n",
            "    for col in imputed_columns\n",
            "]\n",
            "\n",
            "# Add all the daily difference columns to the DataFrame\n",
            "df_with_diffs = df.with_columns(daily_diff_exprs)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df_with_diffs.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "daily_consumption = df_with_diffs"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "3_TlKbNgqxK0"
         },
         "source": [
            "# Data Quality Post Assessment"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Validity"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Define the validity check expressions for each daily diff\n",
            "validity_checks = [\n",
            "    pl.when(\n",
            "        (pl.col(\"CUMMULATIVE_CONSUMPTION\") == 0) | (pl.col(f\"DAILY_DIFF_{col}\") < 0)\n",
            "    )\n",
            "    .then(0)  # Invalid\n",
            "    .otherwise(1)  # Valid\n",
            "    .alias(f\"VALIDITY_{col}\")\n",
            "    for col in imputed_columns\n",
            "]\n",
            "\n",
            "# Apply the validity checks to the DataFrame\n",
            "daily_consumption = daily_consumption.with_columns(validity_checks)\n",
            "\n",
            "daily_consumption.head()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "daily_consumption['VALIDITY_MEAN_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "daily_consumption['VALIDITY_MEDIAN_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "daily_consumption['VALIDITY_FFILL_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "daily_consumption['VALIDITY_BFILL_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "daily_consumption['VALIDITY_LINEAR_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "daily_consumption['VALIDITY_CUBIC_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "daily_consumption['VALIDITY_KNN_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "daily_consumption['VALIDITY_LIN_REG_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# daily_consumption['VALIDITY_SAITS_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.shape[0]"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Accuracy"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "# Z-score method\n",
            "def detect_outliers_zscore(data, threshold=3):\n",
            "    return np.abs(zscore(data)) > threshold\n",
            "\n",
            "# IQR method\n",
            "def detect_outliers_iqr(data):\n",
            "    q1 = np.percentile(data, 25)\n",
            "    q3 = np.percentile(data, 75)\n",
            "    iqr = q3 - q1\n",
            "    lower_bound = q1 - 1.5 * iqr\n",
            "    upper_bound = q3 + 1.5 * iqr\n",
            "    return (data < lower_bound) | (data > upper_bound)\n",
            "\n",
            "# MAD method\n",
            "def detect_outliers_mad(data, threshold=3):\n",
            "    median = np.median(data)\n",
            "    mad = np.median(np.abs(data - median))\n",
            "    modified_z_score = 0.6745 * (data - median) / mad\n",
            "    return np.abs(modified_z_score) > threshold\n",
            "\n",
            "# Isolation Forest method\n",
            "def detect_outliers_isolation_forest(data):\n",
            "    iso = IsolationForest(random_state=42,contamination='auto',)\n",
            "    return iso.fit_predict(data.reshape(-1, 1)) == -1\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Outlier detection workflow for a single device\n",
            "def detect_outliers_per_device(device_data,target,validity_column):\n",
            "    # Mark `VALIDITY=0` as outliers automatically\n",
            "    device_data = device_data.with_columns(\n",
            "        pl.when(pl.col(validity_column) == 0)\n",
            "        .then(True)  # Automatically mark as outlier\n",
            "        .otherwise(False)\n",
            "        .alias(f\"FINAL_OUTLIER_{target}\")\n",
            "    )\n",
            "\n",
            "    # Filter out records with VALIDITY=0 before outlier detection\n",
            "    valid_data = device_data.filter(pl.col(validity_column) == 1)\n",
            "\n",
            "    # Proceed only if valid data exists\n",
            "    if not valid_data.is_empty():\n",
            "      \n",
            "        data = valid_data[target].to_numpy()\n",
            "\n",
            "        # Initialize empty columns for all possible outlier methods\n",
            "        valid_data = valid_data.with_columns(\n",
            "            pl.lit(False).alias(\"OUTLIER_ZSCORE\"),\n",
            "            pl.lit(False).alias(\"OUTLIER_IQR\"),\n",
            "            pl.lit(False).alias(\"OUTLIER_MAD\"),\n",
            "            pl.lit(False).alias(\"OUTLIER_ISO\"),\n",
            "\n",
            "        )\n",
            "\n",
            "       \n",
            "        iqr_outliers = detect_outliers_iqr(data)\n",
            "        mad_outliers = detect_outliers_mad(data)\n",
            "        iso_outliers = detect_outliers_isolation_forest(data)\n",
            "        zscore_outliers = detect_outliers_zscore(data)\n",
            "        valid_data = valid_data.with_columns(\n",
            "            pl.Series(\"OUTLIER_ISO\", iso_outliers),\n",
            "            pl.Series(\"OUTLIER_MAD\", mad_outliers),\n",
            "            # pl.Series(\"OUTLIER_LOF\", lof_outliers),\n",
            "            pl.Series(\"OUTLIER_IQR\", iqr_outliers),\n",
            "        )\n",
            "        # Combine MAD and Isolation Forest using logical AND\n",
            "        final_outlier = np.logical_and(zscore_outliers, np.logical_and(iqr_outliers,np.logical_and(mad_outliers, iso_outliers)))\n",
            "\n",
            "        # Update FINAL_OUTLIER for valid records\n",
            "        valid_data = valid_data.with_columns(\n",
            "            pl.Series(f\"FINAL_OUTLIER_{target}\", final_outlier)\n",
            "        )\n",
            "\n",
            "        # Add missing columns to invalid data with default values\n",
            "        invalid_data = device_data.filter(pl.col(validity_column) == 0).with_columns(\n",
            "            pl.lit(False).alias(\"OUTLIER_ZSCORE\"),\n",
            "            pl.lit(False).alias(\"OUTLIER_IQR\"),\n",
            "            pl.lit(False).alias(\"OUTLIER_MAD\"),\n",
            "            pl.lit(False).alias(\"OUTLIER_ISO\"),\n",
            "  \n",
            "        )\n",
            "\n",
            "        # Combine updated valid data with invalid data\n",
            "        device_data = valid_data.vstack(invalid_data)\n",
            "        \n",
            "    return device_data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "imputed_columns = [\n",
            "    \"MEAN_IMPUTED\", \"MEDIAN_IMPUTED\", \"FFILL_IMPUTED\", \"BFILL_IMPUTED\",\n",
            "    \"LINEAR_IMPUTED\", \"CUBIC_IMPUTED\", \"KNN_IMPUTED\",\n",
            "    \"LIN_REG_IMPUTED\", # \"SAITS_IMPUTED\"\n",
            "]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Mean Imputation"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Group data by DEVICE_ID and apply the workflow\n",
            "result = []\n",
            "for device_id, group in daily_consumption.group_by(\"DEVICE_ID\"):\n",
            "    processed_group = detect_outliers_per_device(group,\"MEAN_IMPUTED\",\"VALIDITY_MEAN_IMPUTED\")\n",
            "    result.append(processed_group)\n",
            "\n",
            "# Concatenate results into a single DataFrame\n",
            "mean_result_df = pl.concat(result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "mean_result_df['FINAL_OUTLIER_MEAN_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Median Imputation"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Group data by DEVICE_ID and apply the workflow\n",
            "median_result = []\n",
            "for device_id, group in daily_consumption.group_by(\"DEVICE_ID\"):\n",
            "    processed_group = detect_outliers_per_device(group,\"MEDIAN_IMPUTED\",\"VALIDITY_MEDIAN_IMPUTED\")\n",
            "    median_result.append(processed_group)\n",
            "# Concatenate results into a single DataFrame\n",
            "median_result_df = pl.concat(median_result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "median_result_df['FINAL_OUTLIER_MEDIAN_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Forward Fill"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Group data by DEVICE_ID and apply the workflow\n",
            "ffill_result = []\n",
            "for device_id, group in daily_consumption.group_by(\"DEVICE_ID\"):\n",
            "    processed_group = detect_outliers_per_device(group,\"FFILL_IMPUTED\",\"VALIDITY_FFILL_IMPUTED\")\n",
            "    ffill_result.append(processed_group)\n",
            "# Concatenate results into a single DataFrame\n",
            "ffill_result_df = pl.concat(ffill_result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "ffill_result_df['FINAL_OUTLIER_FFILL_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Backward Fill"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Group data by DEVICE_ID and apply the workflow\n",
            "bfill_result = []\n",
            "for device_id, group in daily_consumption.group_by(\"DEVICE_ID\"):\n",
            "    processed_group = detect_outliers_per_device(group,\"BFILL_IMPUTED\",\"VALIDITY_BFILL_IMPUTED\")\n",
            "    bfill_result.append(processed_group)\n",
            "# Concatenate results into a single DataFrame\n",
            "bfill_result_df = pl.concat(bfill_result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "bfill_result_df['FINAL_OUTLIER_BFILL_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Cubic Interpolation"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Group data by DEVICE_ID and apply the workflow\n",
            "cubic_result = []\n",
            "for device_id, group in daily_consumption.group_by(\"DEVICE_ID\"):\n",
            "    processed_group = detect_outliers_per_device(group,\"CUBIC_IMPUTED\",\"VALIDITY_CUBIC_IMPUTED\")\n",
            "    cubic_result.append(processed_group)\n",
            "# Concatenate results into a single DataFrame\n",
            "cubic_result_df = pl.concat(cubic_result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "cubic_result_df['FINAL_OUTLIER_CUBIC_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Linear Interpolation"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Group data by DEVICE_ID and apply the workflow\n",
            "linear_result = []\n",
            "for device_id, group in daily_consumption.group_by(\"DEVICE_ID\"):\n",
            "    processed_group = detect_outliers_per_device(group,\"LINEAR_IMPUTED\",\"VALIDITY_LINEAR_IMPUTED\")\n",
            "    linear_result.append(processed_group)\n",
            "# Concatenate results into a single DataFrame\n",
            "linear_result_df = pl.concat(linear_result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "linear_result_df['FINAL_OUTLIER_LINEAR_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### KNN"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Group data by DEVICE_ID and apply the workflow\n",
            "knn_result = []\n",
            "for device_id, group in daily_consumption.group_by(\"DEVICE_ID\"):\n",
            "    processed_group = detect_outliers_per_device(group,\"KNN_IMPUTED\",\"VALIDITY_KNN_IMPUTED\")\n",
            "    knn_result.append(processed_group)\n",
            "# Concatenate results into a single DataFrame\n",
            "knn_result_df = pl.concat(knn_result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "knn_result_df['FINAL_OUTLIER_KNN_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Linear Regression"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Group data by DEVICE_ID and apply the workflow\n",
            "lin_reg_result = []\n",
            "for device_id, group in daily_consumption.group_by(\"DEVICE_ID\"):\n",
            "    processed_group = detect_outliers_per_device(group,\"LIN_REG_IMPUTED\",\"VALIDITY_LIN_REG_IMPUTED\")\n",
            "    lin_reg_result.append(processed_group)\n",
            "# Concatenate results into a single DataFrame\n",
            "lin_reg_result_df = pl.concat(lin_reg_result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "lin_reg_result_df['FINAL_OUTLIER_LIN_REG_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### SAITS"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# # Group data by DEVICE_ID and apply the workflow\n",
            "# saits_reg_result = []\n",
            "# for device_id, group in daily_consumption.group_by(\"DEVICE_ID\"):\n",
            "#     processed_group = detect_outliers_per_device(group,\"SAITS_IMPUTED\",\"VALIDITY_SAITS_IMPUTED\")\n",
            "#     saits_reg_result.append(processed_group)\n",
            "# # Concatenate results into a single DataFrame\n",
            "# saits_result_df = pl.concat(saits_reg_result)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# saits_result_df['FINAL_OUTLIER_SAITS_IMPUTED'].value_counts()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Join All the results"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Start with the main dataframe\n",
            "merged_df = df\n",
            "\n",
            "# Perform sequential joins for each result dataframe\n",
            "merged_df = merged_df.join(mean_result_df.select([\"DEVICE_ID\", \"DATE\", \"VALIDITY_MEAN_IMPUTED\",\"FINAL_OUTLIER_MEAN_IMPUTED\"]),\n",
            "                           on=[\"DEVICE_ID\", \"DATE\"], how=\"left\")\n",
            "\n",
            "merged_df = merged_df.join(median_result_df.select([\"DEVICE_ID\", \"DATE\",\"VALIDITY_MEDIAN_IMPUTED\", \"FINAL_OUTLIER_MEDIAN_IMPUTED\"]),\n",
            "                           on=[\"DEVICE_ID\", \"DATE\"], how=\"left\")\n",
            "\n",
            "merged_df = merged_df.join(lin_reg_result_df.select([\"DEVICE_ID\", \"DATE\", \"VALIDITY_LIN_REG_IMPUTED\",\"FINAL_OUTLIER_LIN_REG_IMPUTED\"]),\n",
            "                           on=[\"DEVICE_ID\", \"DATE\"], how=\"left\")\n",
            "\n",
            "merged_df = merged_df.join(knn_result_df.select([\"DEVICE_ID\", \"DATE\",\"VALIDITY_KNN_IMPUTED\", \"FINAL_OUTLIER_KNN_IMPUTED\"]),\n",
            "                           on=[\"DEVICE_ID\", \"DATE\"], how=\"left\")\n",
            "\n",
            "merged_df = merged_df.join(linear_result_df.select([\"DEVICE_ID\", \"DATE\", \"VALIDITY_LINEAR_IMPUTED\",\"FINAL_OUTLIER_LINEAR_IMPUTED\"]),\n",
            "                           on=[\"DEVICE_ID\", \"DATE\"], how=\"left\")\n",
            "\n",
            "merged_df = merged_df.join(cubic_result_df.select([\"DEVICE_ID\", \"DATE\",\"VALIDITY_CUBIC_IMPUTED\", \"FINAL_OUTLIER_CUBIC_IMPUTED\"]),\n",
            "                           on=[\"DEVICE_ID\", \"DATE\"], how=\"left\")\n",
            "\n",
            "merged_df = merged_df.join(bfill_result_df.select([\"DEVICE_ID\", \"DATE\",\"VALIDITY_BFILL_IMPUTED\", \"FINAL_OUTLIER_BFILL_IMPUTED\"]),\n",
            "                           on=[\"DEVICE_ID\", \"DATE\"], how=\"left\")\n",
            "\n",
            "merged_df = merged_df.join(ffill_result_df.select([\"DEVICE_ID\", \"DATE\", \"VALIDITY_FFILL_IMPUTED\",\"FINAL_OUTLIER_FFILL_IMPUTED\"]),\n",
            "                           on=[\"DEVICE_ID\", \"DATE\"], how=\"left\")\n",
            "\n",
            "# merged_df = merged_df.join(saits_result_df.select([\"DEVICE_ID\", \"DATE\", \"VALIDITY_SAITS_IMPUTED\",\"FINAL_OUTLIER_SAITS_IMPUTED\"]),\n",
            "#                            on=[\"DEVICE_ID\", \"DATE\"], how=\"left\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "merged_df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Nullify the outliers"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "imputed_columns = [\n",
            "    \"MEAN_IMPUTED\", \"MEDIAN_IMPUTED\", \"FFILL_IMPUTED\", \"BFILL_IMPUTED\",\n",
            "    \"LINEAR_IMPUTED\", \"CUBIC_IMPUTED\", \"KNN_IMPUTED\",\n",
            "    \"LIN_REG_IMPUTED\", # \"SAITS_IMPUTED\"\n",
            "]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Define the validity check expressions for each daily diff\n",
            "nullify = [\n",
            "    pl.when(\n",
            "        pl.col(f\"FINAL_OUTLIER_{col}\")\n",
            "    )\n",
            "    .then(None)\n",
            "    .otherwise(pl.col(col))\n",
            "    .alias(col)\n",
            "    for col in imputed_columns\n",
            "]\n",
            "\n",
            "new_df = merged_df.with_columns(nullify)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "0dJFoKHsqxK3"
         },
         "source": [
            "## Dimensions Scoring"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "new_df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "ANim3JgOqxK3"
         },
         "source": [
            "### Accuracy\n",
            "\n",
            "Compute accuracy for each device and the whole dataset"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/"
            },
            "id": "QqG2ZA23qxK3",
            "outputId": "c116bd7c-d668-4506-8eb3-546abb34a0a5",
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "# Ensure unique column names for each DataFrame\n",
            "accuracy_results = []\n",
            "\n",
            "for col in imputed_columns:\n",
            "    # Define the outlier column for this imputed column\n",
            "    outlier_column = f\"FINAL_OUTLIER_{col}\"\n",
            "\n",
            "    # Create a new column for accuracy (1 for accurate, 0 for outlier)\n",
            "    accuracy_col = f\"ACCURACY_{col}\"\n",
            "    df = new_df.with_columns(\n",
            "        (pl.col(outlier_column) == False).cast(pl.Int8).alias(accuracy_col)  # Accurate = 1, Outlier = 0\n",
            "    )\n",
            "\n",
            "    # Compute device-level accuracy\n",
            "    accuracy_df = df.group_by(\"DEVICE_ID\").agg([\n",
            "        pl.sum(accuracy_col).alias(f\"ACCURATE_RECORDS_{col}\"),\n",
            "        pl.count(accuracy_col).alias(f\"TOTAL_RECORDS_{col}\"),\n",
            "        (pl.sum(accuracy_col) / pl.count(accuracy_col) * 100).alias(f\"ACCURACY_PERCENT_{col}\")\n",
            "    ])\n",
            "\n",
            "    # Rename DEVICE_ID to make it unique in each DataFrame\n",
            "    accuracy_df = accuracy_df.rename({\"DEVICE_ID\": f\"DEVICE_ID_{col}\"})\n",
            "\n",
            "    # Append the result to the list\n",
            "    accuracy_results.append(accuracy_df)\n",
            "\n",
            "# Combine all results horizontally\n",
            "final_accuracy_df = pl.concat(accuracy_results, how=\"horizontal\")\n",
            "\n",
            "# Optionally restore the original DEVICE_ID column\n",
            "final_accuracy_df = final_accuracy_df.with_columns(\n",
            "    pl.col(f\"DEVICE_ID_{imputed_columns[0]}\").alias(\"DEVICE_ID\")\n",
            ").drop([f\"DEVICE_ID_{col}\" for col in imputed_columns])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 254
            },
            "id": "SSFkQ3T-qxK3",
            "outputId": "1c36a881-609e-426a-df16-57232099eef7",
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "final_accuracy_df.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Select only DEVICE_ID and the DQS_FINAL columns for each imputation\n",
            "final_accuracy_clean_df = final_accuracy_df.select(\n",
            "    [\"DEVICE_ID\"] + [f\"ACCURACY_PERCENT_{col}\" for col in imputed_columns]\n",
            ")\n",
            "\n",
            "# Display the filtered DataFrame\n",
            "final_accuracy_clean_df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "7Bn7YTIAqxK4"
         },
         "source": [
            "### Validity"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/"
            },
            "id": "VDVDs7hKqxK4",
            "outputId": "f3ecfb78-3f58-4329-c7fd-ad4976fb08c6"
         },
         "outputs": [],
         "source": [
            "# Placeholder for validity results\n",
            "validity_results = []\n",
            "\n",
            "for col in imputed_columns:\n",
            "    # Define the validity column for this imputed column\n",
            "    validity_column = f\"VALIDITY_{col}\"\n",
            "\n",
            "    # Compute device-level validity metrics\n",
            "    validity_df = new_df.group_by(\"DEVICE_ID\").agg([\n",
            "        pl.sum(validity_column).alias(f\"VALID_RECORDS_{col}\"),  # Count valid records\n",
            "        pl.count(validity_column).alias(f\"TOTAL_RECORDS_{col}\"),  # Total records\n",
            "        (pl.sum(validity_column) / pl.count(validity_column) * 100).alias(f\"VALIDITY_PERCENT_{col}\")  # Validity percentage\n",
            "    ])\n",
            "\n",
            "    # Rename DEVICE_ID to make it unique in each DataFrame\n",
            "    validity_df = validity_df.rename({\"DEVICE_ID\": f\"DEVICE_ID_{col}\"})\n",
            "\n",
            "    # Append the result to the list\n",
            "    validity_results.append(validity_df)\n",
            "\n",
            "# Combine all results horizontally\n",
            "final_validity_df = pl.concat(validity_results, how=\"horizontal\")\n",
            "\n",
            "# Restore the original DEVICE_ID column\n",
            "final_validity_df = final_validity_df.with_columns(\n",
            "    pl.col(f\"DEVICE_ID_{imputed_columns[0]}\").alias(\"DEVICE_ID\")\n",
            ").drop([f\"DEVICE_ID_{col}\" for col in imputed_columns])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 254
            },
            "id": "dS20PPh_qxK4",
            "outputId": "e08f90b5-f8ef-4d3f-ed65-9be49fdf88e9"
         },
         "outputs": [],
         "source": [
            "final_validity_df.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Select only DEVICE_ID and the DQS_FINAL columns for each imputation\n",
            "final_validity_clean_df = final_validity_df.select(\n",
            "    [\"DEVICE_ID\"] + [f\"VALIDITY_PERCENT_{col}\" for col in imputed_columns]\n",
            ")\n",
            "\n",
            "# Display the filtered DataFrame\n",
            "final_validity_clean_df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "kdaulLg0qxK4"
         },
         "source": [
            "### Completeness"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Placeholder for completeness results\n",
            "completeness_results = []\n",
            "\n",
            "for col in imputed_columns:\n",
            "    # Define the outlier column for this imputed column\n",
            "    outlier_column = f\"FINAL_OUTLIER_{col}\"\n",
            "\n",
            "    # Step 1: Compute REPORTED_DAYS and EXPECTED_DAYS for each device\n",
            "    completeness_df = new_df.with_columns(\n",
            "        (pl.col(outlier_column) == False).cast(pl.Int8).alias(f\"VALID_DAYS_{col}\")  # Valid days column\n",
            "    ).group_by(\"DEVICE_ID\").agg([\n",
            "        # Sum up the valid days\n",
            "        pl.sum(f\"VALID_DAYS_{col}\").alias(f\"REPORTED_DAYS_{col}\"),\n",
            "        # Calculate the total expected days based on the date range\n",
            "         (((pl.col(\"DATE\").max() - pl.col(\"DATE\").min()).cast(pl.Int64)/ 86400000) + 1)\n",
            "        .alias(f\"EXPECTED_DAYS_{col}\")\n",
            "    ])\n",
            "\n",
            "    # Step 2: Compute Completeness Percentage for each device\n",
            "    completeness_df = completeness_df.with_columns(\n",
            "        ((pl.col(f\"REPORTED_DAYS_{col}\") / pl.col(f\"EXPECTED_DAYS_{col}\")) * 100).alias(f\"COMPLETENESS_PERCENT_{col}\")\n",
            "    )\n",
            "\n",
            "    # Rename DEVICE_ID to make it unique in each DataFrame\n",
            "    completeness_df = completeness_df.rename({\"DEVICE_ID\": f\"DEVICE_ID_{col}\"})\n",
            "\n",
            "    # Append the result to the list\n",
            "    completeness_results.append(completeness_df)\n",
            "\n",
            "# Combine all results horizontally\n",
            "final_completeness_df = pl.concat(completeness_results, how=\"horizontal\")\n",
            "\n",
            "# Restore the original DEVICE_ID column\n",
            "final_completeness_df = final_completeness_df.with_columns(\n",
            "    pl.col(f\"DEVICE_ID_{imputed_columns[0]}\").alias(\"DEVICE_ID\")\n",
            ").drop([f\"DEVICE_ID_{col}\" for col in imputed_columns])\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "final_completeness_df.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Select only DEVICE_ID and the DQS_FINAL columns for each imputation\n",
            "final_completeness_clean_df = final_completeness_df.select(\n",
            "    [\"DEVICE_ID\"] + [f\"COMPLETENESS_PERCENT_{col}\" for col in imputed_columns]\n",
            ")\n",
            "\n",
            "# Display the filtered DataFrame\n",
            "final_completeness_clean_df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Timeliness"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Load the initial data to access the previous metrics. Timeliness is constant, so it's needed to recompute DQS post imputation."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "metrics_df = pl.read_csv('../exports/devices_to_clean.csv', infer_schema_length=100000)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "metrics_df.head()\n",
            "# keep a copy\n",
            "metrics_df_copy = metrics_df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "timeliness_df = metrics_df.select(['DEVICE_ID','AVG_TIMELINESS',])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "timeliness_df.head()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "tGEA_fCLqxK4"
         },
         "source": [
            "### Overall Data Quality Score"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "colab": {
               "base_uri": "https://localhost:8080/",
               "height": 254
            },
            "id": "sOxLjvXcqxK4",
            "outputId": "b13ab176-4217-4585-e275-e6cd024d9ab1"
         },
         "outputs": [],
         "source": [
            "# Placeholder for DQS results across imputed columns\n",
            "dqs_results = []\n",
            "\n",
            "# Timeliness metrics (does not change across imputations)\n",
            "timeliness_metrics = timeliness_df\n",
            "\n",
            "# AHP weights - From Data Quality Assessment\n",
            "ahp_weights = {\n",
            "    \"timeliness\": 0.054102,\n",
            "    \"validity\": 0.310792,\n",
            "    \"completeness\": 0.317553,\n",
            "    \"accuracy\": 0.317553\n",
            "}\n",
            "\n",
            "equal_weight = 0.5\n",
            "ahp_weight = 0.5\n",
            "\n",
            "# Step 1: Iterate over imputed columns and compute DQS for each\n",
            "for col in imputed_columns:\n",
            "    # Combine Completeness, Accuracy, Validity for the current imputed column\n",
            "    metrics_df = final_completeness_df.select([\n",
            "        \"DEVICE_ID\",\n",
            "        f\"COMPLETENESS_PERCENT_{col}\"\n",
            "    ]).join(\n",
            "        final_accuracy_df.select([\"DEVICE_ID\", f\"ACCURACY_PERCENT_{col}\"]),\n",
            "        on=\"DEVICE_ID\"\n",
            "    ).join(\n",
            "        final_validity_df.select([\"DEVICE_ID\", f\"VALIDITY_PERCENT_{col}\"]),\n",
            "        on=\"DEVICE_ID\"\n",
            "    ).join(\n",
            "        timeliness_metrics,\n",
            "        on=\"DEVICE_ID\" \n",
            "    )\n",
            "\n",
            "    # Step 2: Compute Equal Weighting DQS\n",
            "    metrics_df = metrics_df.with_columns(\n",
            "        (\n",
            "            0.25 * pl.col(f\"COMPLETENESS_PERCENT_{col}\") +\n",
            "            0.25 * pl.col(f\"ACCURACY_PERCENT_{col}\") +\n",
            "            0.25 * pl.col(\"AVG_TIMELINESS\") +\n",
            "            0.25 * pl.col(f\"VALIDITY_PERCENT_{col}\")\n",
            "        ).alias(f\"DQS_EQUAL_{col}\")\n",
            "    )\n",
            "\n",
            "    # Step 3: Compute AHP Weighting DQS\n",
            "    metrics_df = metrics_df.with_columns(\n",
            "        (\n",
            "            ahp_weights[\"accuracy\"] * pl.col(f\"ACCURACY_PERCENT_{col}\") +\n",
            "            ahp_weights[\"completeness\"] * pl.col(f\"COMPLETENESS_PERCENT_{col}\") +\n",
            "            ahp_weights[\"timeliness\"] * pl.col(\"AVG_TIMELINESS\") +\n",
            "            ahp_weights[\"validity\"] * pl.col(f\"VALIDITY_PERCENT_{col}\")\n",
            "        ).alias(f\"DQS_AHP_{col}\")\n",
            "    )\n",
            "\n",
            "    # Step 4: Combine Equal and AHP Weighting (Final DQS)\n",
            "    metrics_df = metrics_df.with_columns(\n",
            "        (\n",
            "            (pl.col(f\"DQS_EQUAL_{col}\") * equal_weight) +\n",
            "            (pl.col(f\"DQS_AHP_{col}\") * ahp_weight)\n",
            "        ).alias(f\"DQS_FINAL_{col}\")\n",
            "    )\n",
            "\n",
            "    # Rename all columns (including DEVICE_ID and AVG_TIMELINESS) to make them unique for this imputation column\n",
            "    metrics_df = metrics_df.rename({\n",
            "        \"DEVICE_ID\": f\"DEVICE_ID_{col}\",\n",
            "        \"AVG_TIMELINESS\": f\"AVG_TIMELINESS_{col}\"\n",
            "    })\n",
            "\n",
            "    # Append the result for this imputed column\n",
            "    dqs_results.append(metrics_df)\n",
            "\n",
            "# Step 5: Combine DQS for all imputed columns horizontally\n",
            "final_dqs_df = pl.concat(dqs_results, how=\"horizontal\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "final_dqs_df.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "final_dqs_df = final_dqs_df.rename({\"DEVICE_ID_MEAN_IMPUTED\":\"DEVICE_ID\"})"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Select only DEVICE_ID and the DQS_FINAL columns for each imputation\n",
            "final_dqs_filtered_df = final_dqs_df.select(\n",
            "    [\"DEVICE_ID\",] + [f\"DQS_FINAL_{col}\" for col in imputed_columns]\n",
            ")\n",
            "\n",
            "# Display the filtered DataFrame\n",
            "final_dqs_filtered_df.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "final_dqs_filtered_df['DEVICE_ID'].n_unique()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Visualization"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "final_dqs_filtered_df.write_csv('../exports/final_dqs.csv')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "final_dqs_filtered_df_pd = final_dqs_filtered_df.to_pandas()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Ensure the output directory exists\n",
            "output_dir = \"../visualization/plots\"\n",
            "\n",
            "# Plot 1: Bar Chart of DQS for Each Imputation Method per Device\n",
            "plt.figure(figsize=(18, 6))\n",
            "final_dqs_filtered_df_pd.set_index(\"DEVICE_ID\").plot(kind=\"bar\", figsize=(18, 6))\n",
            "plt.xlabel(\"Device ID\")\n",
            "plt.ylabel(\"Final DQS (%)\")\n",
            "plt.title(\"Final Data Quality Score for Each Imputation Method per Device\")\n",
            "plt.xticks(rotation=90)\n",
            "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
            "plt.legend(title=\"Imputation Methods\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
            "plt.savefig(f\"{output_dir}/final_dqs_per_device.png\", dpi=300, bbox_inches=\"tight\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Plot 2: Boxplot of DQS Scores Across All Imputation Methods\n",
            "plt.figure(figsize=(12, 6))\n",
            "sns.boxplot(data=final_dqs_filtered_df_pd.drop(columns=[\"DEVICE_ID\"]))\n",
            "plt.xlabel(\"Imputation Methods\")\n",
            "plt.ylabel(\"Final DQS (%)\")\n",
            "plt.title(\"Boxplot of DQS Across Different Imputation Methods\")\n",
            "plt.xticks(rotation=45)\n",
            "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
            "plt.savefig(f\"{output_dir}/final_dqs_boxplot.png\", dpi=300, bbox_inches=\"tight\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Plot 3: Histogram of DQS Distribution Across Imputation Methods\n",
            "plt.figure(figsize=(12, 6))\n",
            "final_dqs_filtered_df_pd.drop(columns=[\"DEVICE_ID\"]).plot(kind=\"hist\", alpha=0.5, bins=15, figsize=(12, 6))\n",
            "plt.xlabel(\"Final DQS (%)\")\n",
            "plt.ylabel(\"Frequency\")\n",
            "plt.title(\"Distribution of Final DQS Across Different Imputation Methods\")\n",
            "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
            "plt.legend(title=\"Imputation Methods\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
            "plt.savefig(f\"{output_dir}/final_dqs_histogram.png\", dpi=300, bbox_inches=\"tight\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Plot 4: Heatmap of DQS Scores for Visual Comparison Across Methods (Reversed Color)\n",
            "plt.figure(figsize=(12, 8))\n",
            "sns.heatmap(\n",
            "    final_dqs_filtered_df_pd.set_index(\"DEVICE_ID\"), \n",
            "    annot=True, cmap=\"RdYlGn\", fmt=\".1f\", linewidths=0.5\n",
            ")\n",
            "plt.xlabel(\"Imputation Methods\")\n",
            "plt.ylabel(\"Device ID\")\n",
            "plt.title(\"Heatmap of Final Data Quality Scores Across Imputation Methods\")\n",
            "plt.savefig(f\"{output_dir}/final_dqs_heatmap.png\", dpi=300, bbox_inches=\"tight\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Define groups\n",
            "univariates = [\"DQS_FINAL_FFILL_IMPUTED\", \"DQS_FINAL_BFILL_IMPUTED\",\"DQS_FINAL_MEAN_IMPUTED\", \n",
            "               \"DQS_FINAL_MEDIAN_IMPUTED\", \"DQS_FINAL_LINEAR_IMPUTED\", \"DQS_FINAL_CUBIC_IMPUTED\"]\n",
            "\n",
            "multivariates = [\"DQS_FINAL_KNN_IMPUTED\",\"DQS_FINAL_LIN_REG_IMPUTED\", ]  #\"DQS_FINAL_SAITS_IMPUTED\"\n",
            "\n",
            "# Compute average DQS per category\n",
            "final_dqs_filtered_df_pd[\"DQS_UNIVARIATES\"] = final_dqs_filtered_df_pd[univariates].mean(axis=1)\n",
            "final_dqs_filtered_df_pd[\"DQS_MULTIVARIATES\"] = final_dqs_filtered_df_pd[multivariates].mean(axis=1)\n",
            "\n",
            "# Compute overall average DQS for each category\n",
            "avg_dqs_per_group = {\n",
            "    \"Univariate Methods\": final_dqs_filtered_df_pd[\"DQS_UNIVARIATES\"].mean(),\n",
            "    \"Multivariate Methods\": final_dqs_filtered_df_pd[\"DQS_MULTIVARIATES\"].mean(),\n",
            "\n",
            "}\n",
            "print(avg_dqs_per_group)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "# Convert to DataFrame for plotting\n",
            "avg_dqs_df = pd.DataFrame.from_dict(avg_dqs_per_group, orient=\"index\", columns=[\"Average DQS\"])\n",
            "\n",
            "# Bar Chart: Comparison of Imputation Groups\n",
            "plt.figure(figsize=(8, 6))\n",
            "sns.barplot(x=avg_dqs_df.index, y=avg_dqs_df[\"Average DQS\"], palette=[\"blue\", \"green\", \"red\"])\n",
            "plt.ylabel(\"Average Final DQS (%)\")\n",
            "plt.xlabel(\"Imputation Category\")\n",
            "plt.title(\"Comparison of Data Quality Scores Across Imputation Techniques\")\n",
            "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
            "plt.ylim(75, 100)  # Adjust as needed\n",
            "plt.savefig(f\"{output_dir}/imputation_category_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
            "plt.show()\n",
            "\n",
            "# Boxplot: Distribution of DQS within Each Group\n",
            "plt.figure(figsize=(10, 6))\n",
            "sns.boxplot(data=final_dqs_filtered_df_pd[[\"DQS_UNIVARIATES\", \"DQS_MULTIVARIATES\",]])\n",
            "plt.xlabel(\"Imputation Categories\")\n",
            "plt.ylabel(\"Final DQS (%)\")\n",
            "plt.title(\"Distribution of Data Quality Scores Across Imputation Methods\")\n",
            "plt.xticks(ticks=[0, 1], labels=[\"Univariates Methods\", \"Multivariates Methods\",])\n",
            "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
            "plt.savefig(f\"{output_dir}/imputation_category_boxplot.png\", dpi=300, bbox_inches=\"tight\")\n",
            "plt.show()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "avg_dqs_df.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "avg_dqs_df.to_csv('../exports/avg_dqs_method.csv')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "#### Pre and Post Imputation Comparison"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "metrics_df_copy.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# metrics_df = metrics_df.rename({\"DEVICE_ID_SAITS_IMPUTED\":\"DEVICE_ID\"})\n",
            "\n",
            "# # Ensure metrics_df_copy contains the required columns\n",
            "# source_df = metrics_df_copy.select([\"DEVICE_ID\", \"DQS_FINAL_DEVICE\"])\n",
            "\n",
            "# # Perform the join (left join ensures all DEVICE_IDs in metrics_df are retained)\n",
            "# metrics_df = metrics_df.join(source_df, on=\"DEVICE_ID\", how=\"left\")\n",
            "\n",
            "metrics_df_pd = metrics_df_copy.to_pandas()\n",
            "\n",
            "# Merge previous and post-imputation DQS data\n",
            "comparison_df = final_dqs_filtered_df_pd.merge(metrics_df_pd, on=\"DEVICE_ID\", suffixes=(\"_IMPUTED\", \"_PRE\"))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "scrolled": true
         },
         "outputs": [],
         "source": [
            "# Compute DQS improvement for each imputation method\n",
            "for col in [\n",
            "    \"DQS_FINAL_MEAN_IMPUTED\", \"DQS_FINAL_MEDIAN_IMPUTED\", \"DQS_FINAL_FFILL_IMPUTED\", \n",
            "    \"DQS_FINAL_BFILL_IMPUTED\", \"DQS_FINAL_LINEAR_IMPUTED\", \"DQS_FINAL_CUBIC_IMPUTED\",\n",
            "    \"DQS_FINAL_KNN_IMPUTED\",\"DQS_FINAL_LIN_REG_IMPUTED\" \n",
            "]:\n",
            "    #, \"DQS_FINAL_SAITS_IMPUTED\"\n",
            "    comparison_df[f\"{col}_CHANGE\"] = comparison_df[col] - comparison_df[\"DQS_FINAL_DEVICE\"]\n",
            "\n",
            "# Identify best method per device (the one with highest DQS increase)\n",
            "comparison_df[\"BEST_METHOD\"] = comparison_df[\n",
            "    [\n",
            "        \"DQS_FINAL_MEAN_IMPUTED\", \"DQS_FINAL_MEDIAN_IMPUTED\", \"DQS_FINAL_FFILL_IMPUTED\", \n",
            "        \"DQS_FINAL_BFILL_IMPUTED\", \"DQS_FINAL_LINEAR_IMPUTED\", \"DQS_FINAL_CUBIC_IMPUTED\",\n",
            "        \"DQS_FINAL_KNN_IMPUTED\", \"DQS_FINAL_LIN_REG_IMPUTED\"\n",
            "    ]\n",
            "#, \"DQS_FINAL_SAITS_IMPUTED\"\n",
            "].idxmax(axis=1)\n",
            "\n",
            "# Save comparison results\n",
            "comparison_df.to_csv(\"../exports/dqs_comparison.csv\", index=False)\n",
            "\n",
            "# 1. Boxplot: DQS Improvement per Imputation Method\n",
            "plt.figure(figsize=(12, 6))\n",
            "dqs_change_cols = [col for col in comparison_df.columns if \"_CHANGE\" in col]\n",
            "sns.boxplot(data=comparison_df[dqs_change_cols])\n",
            "plt.xticks(ticks=range(len(dqs_change_cols)), labels=[col.replace(\"_CHANGE\", \"\").replace(\"DQS_FINAL_\", \"\") for col in dqs_change_cols], rotation=45)\n",
            "plt.xlabel(\"Imputation Method\")\n",
            "plt.ylabel(\"DQS Improvement\")\n",
            "plt.title(\"Impact of Imputation Techniques on Data Quality Score\")\n",
            "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
            "plt.savefig(f\"{output_dir}/dqs_improvement_boxplot.png\", dpi=300, bbox_inches=\"tight\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "comparison_df.to_csv('../exports/comparison_df.csv')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# 2. Bar Chart: Average DQS Improvement per Imputation Method\n",
            "avg_dqs_improvement = comparison_df[dqs_change_cols].mean().sort_values(ascending=False)\n",
            "\n",
            "plt.figure(figsize=(12, 6))\n",
            "sns.barplot(x=avg_dqs_improvement.index.str.replace(\"_CHANGE\", \"\").str.replace(\"DQS_FINAL_\", \"\"), y=avg_dqs_improvement.values, palette=\"coolwarm_r\")\n",
            "plt.xlabel(\"Imputation Method\")\n",
            "plt.ylabel(\"Average DQS Improvement\")\n",
            "plt.title(\"Average DQS Improvement Across Imputation Methods\")\n",
            "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
            "plt.xticks(rotation=45)\n",
            "plt.savefig(f\"{output_dir}/dqs_improvement_barplot.png\", dpi=300, bbox_inches=\"tight\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "avg_dqs_improvement"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# 3. Scatter Plot: Pre-Imputation vs. Best Post-Imputation DQS\n",
            "plt.figure(figsize=(8, 6))\n",
            "sns.scatterplot(x=comparison_df[\"DQS_FINAL_DEVICE\"], y=comparison_df[dqs_change_cols].max(axis=1), alpha=0.7, color=\"purple\")\n",
            "plt.xlabel(\"Pre-Imputation DQS\")\n",
            "plt.ylabel(\"Best Post-Imputation DQS\")\n",
            "plt.title(\"Pre-Imputation vs. Best Post-Imputation Data Quality Score\")\n",
            "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
            "plt.savefig(f\"{output_dir}/dqs_scatter_best.png\", dpi=300, bbox_inches=\"tight\")\n",
            "plt.show()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# 4. Countplot: Best Performing Imputation Method for Each Device\n",
            "plt.figure(figsize=(12, 6))\n",
            "sns.countplot(y=comparison_df[\"BEST_METHOD\"], order=comparison_df[\"BEST_METHOD\"].value_counts().index, palette=\"coolwarm\")\n",
            "plt.xlabel(\"Number of Devices\")\n",
            "plt.ylabel(\"Best Performing Imputation Method\")\n",
            "plt.title(\"Best Imputation Method for Each Device\")\n",
            "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
            "plt.savefig(f\"{output_dir}/best_imputation_method_countplot.png\", dpi=300, bbox_inches=\"tight\")\n",
            "plt.show()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "colab": {
         "collapsed_sections": [
            "hyDedPc8HvSa",
            "3VpS-O9vHvSb",
            "J4tcXDKnhh6q",
            "xA9no9XJPl2y",
            "m1HOmuf1HvSo",
            "rj5QHprRHvSo",
            "sj2dbOvFHvSp",
            "JnRkg4dbHvSr",
            "gPGlpPwjr3n2",
            "bB1UKw1osLp7"
         ],
         "provenance": [],
         "toc_visible": true
      },
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.15"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
